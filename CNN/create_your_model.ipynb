{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import re\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from tqdm import tqdm\n",
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils import get_column_letter\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage\n",
    "import seaborn as sns\n",
    "import tempfile\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RENAME THIS FILE WITH THE NAME OF THE METABOLITE YOU WANT ###\n",
    "\n",
    "def get_metabolite_name():\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Get the parent directory name (which should be the metabolite name)\n",
    "    metabolite_name = os.path.basename(current_dir)\n",
    "    \n",
    "    return metabolite_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    metabolite_name = get_metabolite_name()\n",
    "    version = 1 ## SELECT THE VERSION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_path(metabolite_name, path_type):\n",
    "    base_dir = r'C:\\Users\\PC\\Documents\\BIOSFER\\CNN' # modify the path here\n",
    "    \n",
    "    if path_type in [\"invalid\", \"valid\"]:\n",
    "        return os.path.join(base_dir, \"data\", metabolite_name, path_type)\n",
    "    elif path_type == \"models\":\n",
    "        return os.path.join(base_dir, \"models\", metabolite_name)\n",
    "    elif path_type == \"excel\":\n",
    "        return os.path.join(base_dir, f\"model_results_{metabolite_name}.xlsx\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid path type\")\n",
    "    \n",
    "path_invalid = construct_path(metabolite_name, \"invalid\")\n",
    "path_valid = construct_path(metabolite_name, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    data = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(path, filename)\n",
    "            # Read PNG with all channels\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            # Adding this correction turns the number of channels from 4 to 3, which affects the condition below!!\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            if img is not None and img.shape == (600, 800, 3):\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                data.append((img, label, filename))\n",
    "    df = pd.DataFrame(data, columns=['Image', 'Label', 'Filename'])\n",
    "    df.set_index('Filename', inplace=True)\n",
    "\n",
    "    return images, labels, df\n",
    "\n",
    "\n",
    "# Load NA (invalid) images\n",
    "na_images, na_labels, df_0 = load_images(path_invalid, 0)  # 0 for invalid\n",
    "\n",
    "# Load normal (valid) images\n",
    "normal_images, normal_labels, df_1 = load_images(path_valid, 1)  # 1 for valid\n",
    "\n",
    "# Combine the data\n",
    "X = na_images + normal_images\n",
    "Y = na_labels + normal_labels\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Merging the two dfs\n",
    "df = pd.concat([df_0, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better practice is to create dataframes, and have each row with its identifier, the image, and the label\n",
    "print(\"Invalid df description\")\n",
    "print(\"----------------------------------\")\n",
    "print(df_0.shape)\n",
    "print(df_0.dtypes)\n",
    "print(\" \")\n",
    "print(\"Valid df description\")\n",
    "print(\"----------------------------------\")\n",
    "print(df_1.shape)\n",
    "print(df_1.dtypes)\n",
    "print(\" \")\n",
    "print(\"Valid complete df description\")\n",
    "print(\"----------------------------------\")\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load YAML config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(metabolite_name, version):\n",
    "    yaml_file = f'config_{metabolite_name.lower()}.yml'\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    \n",
    "    # Convert version to integer if it's a whole number\n",
    "    version_int = int(version) if isinstance(version, float) and version.is_integer() else version\n",
    "    \n",
    "    if version_int not in config['versions']:\n",
    "        raise ValueError(f\"Version {version} not found in config file\")\n",
    "    \n",
    "    return config['versions'][version_int], str(version)\n",
    "\n",
    "config, version_str = load_config(metabolite_name, version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images with normalization and standardization\n",
    "def preprocess_images(images, coords, crop_size, resize_shape):\n",
    "    processed_images = []\n",
    "\n",
    "    for img in images:\n",
    "        # Crop the image\n",
    "        cropped_img = img[coords[0]:(\n",
    "            coords[0] + crop_size[0]), coords[1]:(coords[1]+crop_size[1])]\n",
    "\n",
    "        # Resize the image\n",
    "        resized_img = cv2.resize(\n",
    "            cropped_img, resize_shape, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Normalize pixel values\n",
    "        normalized_img = resized_img.astype(np.float32) / 255.0\n",
    "\n",
    "        processed_images.append(normalized_img)\n",
    "\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = config['preprocess']['coords']\n",
    "crop_size = config['preprocess']['crop_size']\n",
    "resize_shape = tuple(config['preprocess']['resize_shape'])\n",
    "\n",
    "\n",
    "X_processed = preprocess_images(\n",
    "    df['Image'].tolist(), coords, crop_size, resize_shape)\n",
    "\n",
    "df['Processed'] = X_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure splits contain at least one NA sample\n",
    "def ensure_na_in_split(X, Y, na_label=0):\n",
    "\n",
    "    # Shuffle the data\n",
    "    np.random.seed(42)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "\n",
    "    # Split data into training (80%), validation (15%), and test (5%)\n",
    "    # First, split into training (80%) and temporary (20%)\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "    # Second, split the temporary set into validation (15% of total) and test (5% of total)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "        X_temp, Y_temp, test_size=0.25, random_state=42, stratify=Y_temp)\n",
    "\n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test\n",
    "\n",
    "# Split and ensure each set has at least one NA sample\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = ensure_na_in_split(\n",
    "    df['Processed'], df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.stack(X_train.values)\n",
    "X_val_array = np.stack(X_val.values)\n",
    "X_test_array = np.stack(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow tensors\n",
    "X_train_tensor = tf.convert_to_tensor(X_train_array, dtype=tf.float32)\n",
    "X_val_tensor = tf.convert_to_tensor(X_val_array, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test_array, dtype=tf.float32)\n",
    "\n",
    "Y_train_tensor = tf.convert_to_tensor(Y_train, dtype=tf.float32)\n",
    "Y_val_tensor = tf.convert_to_tensor(Y_val, dtype=tf.float32)\n",
    "Y_test_tensor = tf.convert_to_tensor(Y_test, dtype=tf.float32)\n",
    "\n",
    "# Print the shapes of the arrays\n",
    "print(f'Shape of X_train_tensor: {X_train_tensor.shape}')\n",
    "print(f'Shape of X_val_tensor: {X_val_tensor.shape}')\n",
    "print(f'Shape of X_test_tensor: {X_test_tensor.shape}')\n",
    "print(f'Shape of Y_train_tensor: {Y_train_tensor.shape}')\n",
    "print(f'Shape of Y_val_tensor: {Y_val_tensor.shape}')\n",
    "print(f'Shape of Y_test_tensor: {Y_test_tensor.shape}')\n",
    "\n",
    "# Print the number of NA samples in each split\n",
    "print(f'Number of NA samples in Y_train: {np.sum(Y_train == 0)}')\n",
    "print(f'Number of NA samples in Y_val: {np.sum(Y_val == 0)}')\n",
    "print(f'Number of NA samples in Y_test: {np.sum(Y_test == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test and Y_test are your final test set arrays\n",
    "\n",
    "# First, let's create a DataFrame that combines all the information\n",
    "df_all = df.reset_index()  # Reset index to make 'Filename' a column\n",
    "df_all['Processed'] = df_all['Image'].apply(lambda x: preprocess_images([x], coords, crop_size, resize_shape)[0])\n",
    "\n",
    "# Now, we need to find which rows in df_all correspond to X_test\n",
    "# We'll do this by comparing the 'Processed' images\n",
    "\n",
    "def find_matching_filenames(X_test, df_all):\n",
    "    filenames = []\n",
    "    for test_img in X_test:\n",
    "        # Find the index of the matching processed image\n",
    "        matching_index = df_all['Processed'].apply(lambda x: np.array_equal(x, test_img)).idxmax()\n",
    "        filenames.append(df_all.loc[matching_index, 'Filename'])\n",
    "    return filenames\n",
    "\n",
    "# Get the filenames for X_test\n",
    "test_filenames = find_matching_filenames(X_test, df_all)\n",
    "\n",
    "# Now we can get the filenames for label 0 in the test set\n",
    "label_0_indices = np.where(Y_test == 0)[0]\n",
    "label_0_filenames = [test_filenames[i] for i in label_0_indices]\n",
    "\n",
    "# Print the filenames\n",
    "print(\"Test set filenames with label 0:\")\n",
    "for filename in label_0_filenames:\n",
    "    print(filename)\n",
    "\n",
    "# Print the count\n",
    "print(f\"\\nTotal number of test samples with label 0: {len(label_0_filenames)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(config['code'])\n",
    "model.summary()  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(config['training'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display and DL activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_filtered(name_image, model, layer_name, image):\n",
    "    inp = model.inputs \n",
    "    out1 = model.get_layer(layer_name).output  \n",
    "    feature_map_1 = tf.keras.Model(inputs=inp, outputs=out1)  \n",
    "    # Resize the image to match the model's input shape\n",
    "    input_img = tf.image.resize(image, (X_train_tensor.shape[1], X_train_tensor.shape[2]))\n",
    "    input_img = np.expand_dims(input_img, axis=0)      \n",
    "    f = feature_map_1.predict(input_img) \n",
    "    dim = f.shape[3]\n",
    "    print(f'{layer_name} | Features Shape: {f.shape}')\n",
    "    print(f'Dimension {dim}')\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    if not os.path.exists(f'results_{name_image}'):\n",
    "        os.makedirs(f'results_{name_image}')        \n",
    "    for i in range(dim):\n",
    "        ax = fig.add_subplot(dim//2, dim//2 + dim%2, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(f[0, :, :, i])\n",
    "        plt.imsave(f'results_{name_image}/{name_image}_{layer_name}_{i}.jpg', f[0, :, :, i])\n",
    "    plt.show()\n",
    "\n",
    "# Display activation maps for ten images in the training set\n",
    "num_images_to_visualize = 10\n",
    "for i in range(num_images_to_visualize):\n",
    "    original_index = df[df['Processed'].apply(lambda x: np.array_equal(x, X_train_tensor[i]))].index[0]\n",
    "    original_image = df.loc[original_index, 'Image']\n",
    "    \n",
    "    # Display original image\n",
    "    plt.axis('off')\n",
    "    plt.imshow(original_image)\n",
    "    plt.show()\n",
    "    \n",
    "    # Display activation maps for each layer\n",
    "    layers = ['conv2d_1','max_pooling2d_1', 'conv2d_2','max_pooling2d_2', 'conv2d_3','max_pooling2d_3']\n",
    "    for layer in layers:\n",
    "        display_image_filtered(f'train_image_{i}', model, layer, original_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_filter(model, layer_name):\n",
    "    # Get layer weights\n",
    "    layer = model.get_layer(layer_name)\n",
    "    filter, bias = layer.get_weights()\n",
    "    dim = filter.shape[3]\n",
    "    \n",
    "    print(f'{layer_name} | Filter Shape: {filter.shape} Bias Shape: {bias.shape}')\n",
    "    print(f'Dimension {dim}')\n",
    "    \n",
    "    # Normalize filter values\n",
    "    f_min, f_max = filter.min(), filter.max()\n",
    "    filter = (filter - f_min) / (f_max - f_min)\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    rows = dim // 2\n",
    "    cols = dim // 2 + dim % 2\n",
    "    \n",
    "    # Create figure with proper size and spacing\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    \n",
    "    for i in range(dim):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        \n",
    "        # Get the filter slice and handle dimensionality\n",
    "        filter_slice = filter[:, :, :, i]\n",
    "        \n",
    "        # For first layer (RGB)\n",
    "        if filter_slice.shape[-1] == 3:\n",
    "            display_data = filter_slice\n",
    "        # For subsequent layers (single channel)\n",
    "        else:\n",
    "            # Take the first channel if multiple channels exist\n",
    "            if len(filter_slice.shape) == 3:\n",
    "                display_data = filter_slice[:, :, 0]\n",
    "            else:\n",
    "                display_data = filter_slice\n",
    "                \n",
    "        # Display filter\n",
    "        im = ax.imshow(display_data, cmap='viridis')\n",
    "        \n",
    "        # Create colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(im, cax=cax)\n",
    "        \n",
    "        # Add title with value range\n",
    "        ax.set_title(f'Filter {i+1}\\nRange: [{display_data.min():.2f}, {display_data.max():.2f}]')\n",
    "        \n",
    "        # Remove axis ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle(f'Filters from layer: {layer_name}', fontsize=16, y=0.95)\n",
    "    plt.show()\n",
    "\n",
    "# Display filters for each convolutional layer\n",
    "def display_all_filters(model):\n",
    "    conv_layers = [layer for layer in model.layers if 'conv2d' in layer.name]\n",
    "    for layer in conv_layers:\n",
    "        display_filter(model, layer.name)\n",
    "\n",
    "display_all_filters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('module://matplotlib_inline.backend_inline')\n",
    "\n",
    "# Plot Performance\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'],label='Training Accuracy')  # type: ignore\n",
    "plt.plot(history.history['val_accuracy'],label='Validation Accuracy')  # type: ignore\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # type: ignore\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')  # type: ignore\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(  # type: ignore\n",
    "    X_test_tensor, Y_test_tensor, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predict and Generate Classification Report\n",
    "\n",
    "y_pred = model.predict(X_test_tensor)  # type: ignore\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_pred_classes))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_probabilities(df, probabilities, save_path=None):\n",
    "    probabilities = np.squeeze(probabilities)\n",
    "    num_images = len(df)\n",
    "    grid_size = int(num_images**0.5)\n",
    "    if grid_size**2 < num_images:\n",
    "        grid_size += 1\n",
    "\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(100, 100))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        img = row['Image']  # Use the original image from the DataFrame\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Hide axis\n",
    "\n",
    "        # Determine the color based on the probability\n",
    "        probability = float(probabilities[i])\n",
    "        if probability >= 0.995:\n",
    "            color = 'green'\n",
    "        elif 0.05 < probability < 0.995:\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            color = 'red'\n",
    "\n",
    "        prob_text = f\"{probability * 100:.4f}%\"\n",
    "        axes[i].text(10, 20, prob_text, color='white', fontsize=60,\n",
    "                     bbox=dict(facecolor=color, alpha=0.5))\n",
    "\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='png')\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "# Assuming X_test contains the filenames of the test set images\n",
    "X_test_filenames = X_test.index if hasattr(X_test, 'index') else X_test\n",
    "\n",
    "# Create a DataFrame for the test set\n",
    "df_test = df.loc[X_test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test_tensor)  # type: ignore\n",
    "# Plot original images with probabilities\n",
    "plot_images_with_probabilities(df_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Excel table compile model result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_results_to_excel(version, model, history, X_test, Y_test, X_test_tensor, Y_test_tensor, df_test, \n",
    "                                   metabolite_name,  # This parameter is already included\n",
    "                                   excel_path=None):\n",
    "    if excel_path is None:\n",
    "        excel_path = f'model_results_{metabolite_name}.xlsx'\n",
    "    matplotlib.use('Agg')\n",
    "     \n",
    "    # Load the specific version of the configuration\n",
    "    try:\n",
    "        config, version_str = load_config(metabolite_name, version)  # Use both arguments here\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading configuration: {e}\")\n",
    "        return\n",
    "\n",
    "    # Load existing Excel file or create a new one\n",
    "    try:\n",
    "        workbook = openpyxl.load_workbook(excel_path)\n",
    "    except FileNotFoundError:\n",
    "        workbook = openpyxl.Workbook()\n",
    "\n",
    "    # Get or create the sheet for this version\n",
    "    sheet_name = f'Version {version}'\n",
    "    if sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        # Clear the existing content\n",
    "        for row in sheet[sheet.dimensions]:\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "    else:\n",
    "        sheet = workbook.create_sheet(title=sheet_name)\n",
    "\n",
    "    # 1. Model Summary\n",
    "    sheet['A1'] = 'Model Summary'\n",
    "    stringlist = []\n",
    "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    summary_string = \"\\n\".join(stringlist)\n",
    "\n",
    "    # Save the summary to a temporary text file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8', suffix='.txt') as tmpfile:\n",
    "        tmpfile.write(summary_string)\n",
    "        tmpfile_path = tmpfile.name\n",
    "\n",
    "    # Convert the text file to an image\n",
    "    img_buf = BytesIO()\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.text(0.01, 0.99, summary_string, va='top', ha='left', wrap=True, fontsize=10, family='monospace')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(img_buf, format='png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    img_buf.seek(0)\n",
    "\n",
    "    # Insert the image into the Excel sheet\n",
    "    img = Image(img_buf)\n",
    "    sheet.add_image(img, 'A2')\n",
    "        \n",
    "    # 2. Training History\n",
    "    sheet['M1'] = 'Training History'\n",
    "    sheet['M2'] = 'Accuracy'\n",
    "    sheet['N2'] = 'Loss'\n",
    "    sheet['O2'] = 'Val Accuracy'\n",
    "    sheet['P2'] = 'Val Loss'\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    for r, row in enumerate(history_df.values, start=3):\n",
    "        for c, value in enumerate(row, start=13):\n",
    "            sheet.cell(row=r, column=c, value=value)\n",
    "\n",
    "    # 3. Performance Plots\n",
    "\n",
    "    # Model Accuracy Plot\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    img_buf = BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    plt.close()\n",
    "    img_buf.seek(0)\n",
    "    img = Image(img_buf)\n",
    "    sheet.add_image(img, 'R1')\n",
    "\n",
    "    # Model Loss Plot\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    img_buf = BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    plt.close()\n",
    "    img_buf.seek(0)\n",
    "    img = Image(img_buf)\n",
    "    sheet.add_image(img, 'R22')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    y_pred = model.predict(X_test_tensor)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    cm = confusion_matrix(Y_test, y_pred_classes)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    img_buf = BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    plt.close()\n",
    "    img_buf.seek(0)\n",
    "    img = Image(img_buf)\n",
    "    sheet.add_image(img, 'R43')\n",
    "\n",
    "    # 4. Image Probabilities\n",
    "    sheet['AD1'] = 'Image Probabilities'\n",
    "    img_buf = BytesIO()\n",
    "    plot_images_with_probabilities(df_test, y_pred, save_path=img_buf)\n",
    "    img_buf.seek(0)\n",
    "    img = Image(img_buf)\n",
    "    sheet.add_image(img, 'AD2')\n",
    "\n",
    "    # 5. Model Code\n",
    "    sheet['A35'] = 'Model Code'\n",
    "    model_code = config.get('code', 'Model code not available') if isinstance(config, dict) else 'Model code not available'\n",
    "    model_code_lines = model_code.split('\\n')\n",
    "    for i, line in enumerate(model_code_lines, start=36):\n",
    "        sheet.cell(row=i, column=1, value=line)\n",
    "\n",
    "    # 6. Training Code\n",
    "    sheet['A76'] = 'Training Code'\n",
    "    training_code = config.get('training', 'Training code not available') if isinstance(config, dict) else 'Training code not available'\n",
    "    training_code_lines = training_code.split('\\n')\n",
    "    for i, line in enumerate(training_code_lines, start=77):\n",
    "        sheet.cell(row=i, column=1, value=line)\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(excel_path)\n",
    "    print(f\"Results for version {version} compiled and saved to {excel_path}\")\n",
    "\n",
    "compile_model_results_to_excel(version, model, history, X_test, Y_test, X_test_tensor, Y_test_tensor, df_test, \n",
    "                               metabolite_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Save the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_dir = construct_path(metabolite_name, \"models\")\n",
    "model_filename = f'model_{metabolite_name}_v{version_str}.keras'\n",
    "model_save_path = os.path.join(model_save_dir, model_filename)\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "model.save(model_save_path)  # Attempt to save the model\n",
    "\n",
    "print(f\"Model saved as: {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
