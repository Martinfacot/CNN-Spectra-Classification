versions:
  1:
    # Original version
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.001
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  2:
    # Changed learning rate
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.01  # Changed from 0.001
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  3:
    # Changed input size, increased network capacity, adjusted learning rate, more epochs
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [224, 224]  # Changed from [320, 320]
    model:
      input_shape: [224, 224, 3]  # Changed to match resize_shape
      layers:
        - type: Conv2D
          filters: 32  # Increased from 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 64  # Increased from 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32  # Increased from 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 512  # Increased from 256
          activation: relu
          dropout: 0.5  # Increased from 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.005  # Changed from 0.01
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 50  # Increased from 25
  4:
    # Changed kernel sizes, activation function, and optimizer
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [5, 5]  # Changed from [3, 3]
          strides: 1
          activation: elu  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [5, 5]  # Changed from [3, 3]
          activation: elu  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [5, 5]  # Changed from [3, 3]
          strides: 1
          activation: elu  # Changed from relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: elu  # Changed from relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: RMSprop  # Changed from Adam
      learning_rate: 0.001
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  5:
    # Added BatchNormalization, changed loss function, added AUC metric
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: BatchNormalization  # Added BatchNormalization
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: BatchNormalization  # Added BatchNormalization
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: BatchNormalization  # Added BatchNormalization
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.01   # Changed
      loss: binary_focal_crossentropy  # Changed from binary_crossentropy
      metrics: [accuracy, AUC]  # Added AUC metric
      epochs: 25
  6:
    # Changed activation, added layer, used GlobalAveragePooling2D
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: leaky_relu  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: leaky_relu  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 64  # Added an extra Conv2D layer
          kernel_size: [3, 3]
          activation: leaky_relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: leaky_relu  # Changed from relu
          pool_size: [2, 2]
        - type: GlobalAveragePooling2D  # Changed from Flatten
        - type: Dense
          units: 256
          activation: leaky_relu  # Changed from relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.01  # Changed
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  7:
    # Used SeparableConv2D, changed optimizer
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: SeparableConv2D  # Changed from Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: SeparableConv2D  # Changed from Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: SeparableConv2D  # Changed from Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adamax  # Changed from Adam
      learning_rate: 0.01  # Changed
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  8:
    # Added early stopping
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.001   
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 40
      early_stopping:  # Added early stopping
        monitor: val_loss
        patience: 15
  9:
    # Changed activation function, changed optimizer
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: swish  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: swish  # Changed from relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: swish  # Changed from relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: swish  # Changed from relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: AdamW  # Changed from Adam
      learning_rate: 0.001
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  10:
    # Added ExponentialDecay learning rate schedule
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    model:
      input_shape: [320, 320, 3]
      layers:
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 256
          activation: relu
          dropout: 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate:  # Added ExponentialDecay learning rate schedule
        type: ExponentialDecay
        initial_learning_rate: 0.0001
        decay_steps: 100000
        decay_rate: 0.96
        staircase: True
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 25
  11:
    # Changed input size, increased network capacity, adjusted learning rate, more epochs
    preprocessing:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [256, 256]  # Changed from [320, 320]
    model:
      input_shape: [256, 256, 3]  # Changed to match resize_shape
      layers:
        - type: Conv2D
          filters: 32  # Increased from 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 64  # Increased from 32
          kernel_size: [3, 3]
          activation: relu
          pool_size: [2, 2]
        - type: Conv2D
          filters: 32  # Increased from 16
          kernel_size: [3, 3]
          strides: 1
          activation: relu
          pool_size: [2, 2]
        - type: Flatten
        - type: Dense
          units: 512  # Increased from 256
          activation: relu
          dropout: 0.5  # Increased from 0.3
        - type: Dense
          units: 1
          activation: sigmoid
    training:
      optimizer: Adam
      learning_rate: 0.001  # Changed from 0.01
      loss: binary_crossentropy
      metrics: [accuracy]
      epochs: 50  # Increased from 25
