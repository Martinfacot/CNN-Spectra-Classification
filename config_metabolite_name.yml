versions:
  1: # original model
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=25,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      verbose=1)

  1.5: # number of epochs 25-->50
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=50,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      verbose=1)

  2: # early stopping & increase the number of epochs
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  2.5: # early stopping & increase the number of epochs + resize shape (320 --> 256)
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [256, 256]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  3: # L2
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu',  kernel_regularizer=tf.keras.regularizers.l2(0.001)),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  4: # L2 x2 network capacity
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu',  kernel_regularizer=tf.keras.regularizers.l2(0.001)),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  7: # increased network capacity x2
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  7.1: # add fully connected layer 
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)                     

  8: # version 6 + 7 = implement class weights + Changed input size (320-->256), increased network capacity x2
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [256, 256]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
      
      def calculate_class_weights(y):
        total = len(y)
        neg = np.sum(y == 0)
        pos = np.sum(y == 1)
        weight_for_0 = (1 / neg) * (total / 2.0)
        weight_for_1 = (1 / pos) * (total / 2.0)
        class_weight = {0: weight_for_0, 1: weight_for_1}
        return class_weight

      class_weights = calculate_class_weights(Y_train_tensor)


    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=50,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      class_weight=class_weights,
                      verbose=1)

  9: # Batch Normalization, Increased Convolutional Layers, Increased Filters, L2 Regularization,
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [256, 256]
    code: |
      model = tf.keras.Sequential([

        tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        tf.keras.layers.Flatten(),

        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        tf.keras.layers.Dropout(0.5),

        tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=50,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      verbose=1)

  10: # early stopping & increase the number of epochs + add a layer (drop out 0.5)
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=20,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  11: # early stopping & increase the number of epochs + add a layer (drop out 0.5) + last layer x2 + patience (12)
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=12,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  12: # v10 + add drop out at each layer (patience=20)
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.2),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.3),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.4),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=20,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  13: # v12 + L2 regularization (strength = 0.001) default = 0.01
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      l2_regularizer = tf.keras.regularizers.l2(0.001)

      model = tf.keras.Sequential([

          tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

          tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.2),

          tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.3),

          tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.4),

          tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.5),

          tf.keras.layers.Flatten(),

          tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.Dropout(0.5),

          tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  13.5: # v12 + L2 regularization default = 0.01
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [320, 320]
    code: |
      l2_regularizer = tf.keras.regularizers.l2(0.01)

      model = tf.keras.Sequential([

          tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

          tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.2),

          tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.3),

          tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.4),

          tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
          tf.keras.layers.Dropout(0.5),

          tf.keras.layers.Flatten(),

          tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2_regularizer),
          tf.keras.layers.Dropout(0.5),

          tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])
     
      early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True)

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=70,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      callbacks=[early_stopping],
                      verbose=1)

  14: # softmax
    preprocess:
      coords: [70, 108]
      crop_size: [465, 605]
      resize_shape: [256, 256]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(2, activation='softmax')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss=tf.keras.losses.CategoricalCrossentropy(),
                metrics=['accuracy'])

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=50,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      verbose=1)

  15: # dog and cat
    preprocess:
      resize_shape: [256, 256]
    code: |
      model = tf.keras.Sequential([

            tf.keras.layers.Input(shape=[X_train_tensor.shape[1], X_train_tensor.shape[2], X_train_tensor.shape[3]]),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),

            tf.keras.layers.Dense(1, activation='sigmoid')])

      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy'])

    training: |
      history = model.fit(X_train_tensor, Y_train_tensor,
                      epochs=50,
                      validation_data=(X_val_tensor, Y_val_tensor),
                      verbose=1)

